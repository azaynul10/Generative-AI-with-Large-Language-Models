# Generative AI with Large Language Models: Dialogue Summarization Lab

## Description
Welcome to the Dialogue Summarization Lab, part of the "Generative AI with Large Language Models" course by AWS and DeepLearning.AI! This project showcases the power of FLAN-T5 in summarizing conversations using various prompt engineering techniques. Dive into the world of natural language processing and experience firsthand how large language models can transform raw dialogues into concise, meaningful summaries.

## Table of Contents
- [Installation](#installation)
- [Usage](#usage)
- [Features](#features)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgements](#acknowledgements)

## Installation
To get started with this lab, follow these steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/azaynul10/generative-ai-llm-dialogue-summarization.git
   ```
2. Navigate to the project directory:
   ```bash
   cd generative-ai-llm-dialogue-summarization
   ```
3. Install the required dependencies:
   ```bash
   pip install torch torchdata transformers datasets
   ```

## Usage
1. Open the Jupyter notebook in the `lab1` directory.
2. Run the cells to load the DialogSum dataset and initialize the FLAN-T5 model.
3. Experiment with different prompt engineering techniques:
   - Zero-shot learning
   - One-shot learning
   - Few-shot learning
4. Adjust the sampling temperature to see how it affects the generated summaries.
5. Analyze the results and compare the effectiveness of different approaches.

## Features
- **FLAN-T5 Model**: Utilize the powerful FLAN-T5 model for dialogue summarization.
- **DialogSum Dataset**: Work with a rich, public dataset of conversations.
- **Prompt Engineering**: Explore zero-shot, one-shot, and few-shot learning techniques.
- **Customizable Parameters**: Experiment with sampling temperature and other settings.
- **Python-based**: Leverages popular libraries like PyTorch, Transformers, and Datasets.

## Contributing
We welcome contributions to improve this lab! Here's how you can help:

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![giphy (8)](https://github.com/user-attachments/assets/b5b5ac0a-796a-46af-8051-b0532db0a2c2)



## Acknowledgements
- AWS and DeepLearning.AI for creating this insightful course
- Hugging Face for providing the Transformers library and FLAN-T5 model
- The creators of the DialogSum dataset

Happy summarizing! ðŸš€ðŸ“š
